The study-enator (goofy name...I know) is a long term goal that will eventually analyze how focused I am
while studying. I have attached a camera module onto my raspberry pi and it will feed live video as input
to a neural network that will make an inference as to whether or not I am putting forth quality effort while seated.
This project requires me to learn how to train a neural network to detect certain motions. I have decided to break this project
into X parts. 

1) Use tutorial code that utilizes a neural network to detect faces in images
2) Apply that tutorial code to the live feed video coming from my raspberry pi
3) Detect my face in video with the raspberry pi
  i) Purchased a webcam and can now feed video feed from either PiCamera or Webcam
4) Retrain the deep learning model to detect how focused I am rather than my face (In Progress)
  i) Currently learning how to train models in my other repo (PaperImplementations)

Credit for the code placing box around face from detections goes to Adrian Rosebrock from pyimagesearch.com
